<h1 align="center">
  <br />
  AI for Cybersecurity Attribution
  <br />

### ðŸ¤– Using Fine-Tuned Small Language Models on Synthetic Data to Enhance APT Attribution and TTP Chaining

<p align="justify"> Advanced Persistent Threatsâ€¯(APTs) remain notoriously hard to attribute because publicly available threatâ€‘intelligence traces are both scarce and volatile. Conventional analyst workflows, which rely on laborâ€‘intensive Indicatorâ€‘ofâ€‘Compromise (IoC) matching or malware lineage analysis, struggle to keep pace with fastâ€‘evolving attacker tradecraft. To break this data bottleneck, the thesis proposes a resourceâ€‘efficient pipeline that synthesizes highâ€‘fidelity, chronologically ordered attack narratives and exploits them to train a compact language model capable of nearâ€‘realâ€‘time attribution</p>

<p align="justify">The workflow begins by distilling an APTâ€¯Ã—â€¯TTP knowledge base from the MITREâ€¯ATT&CK framework. Large Language Models (GPTâ€‘4) are then prompted to generate analystâ€‘style narratives that embed those tactics, techniques, and procedures in realistic timelines. A TFâ€‘IDF based distinctiveness score boosts rare yet discriminative techniques, while a NaÃ¯veâ€¯Bayes posterior filter discards hallucinated or logically inconsistent chains producing a balanced, highâ€‘quality synthetic corpus that explicitly addresses longâ€‘tail data sparsity.</p>
<p align="justify">A Llamaâ€¯3.1â€¯8B Small Language Model is fineâ€‘tuned with 4â€‘bitâ€¯LoRA adapters, modifying fewer thanâ€¯1â€¯% of its parameters. This lightweight adaptation lets the model infer an attackerâ€™s most likely APT group and, when required, emit a structured JSON explanation that aligns each observed technique to an ATT&CK Killâ€‘Chain stage all while running on commodity GPUs. Experimental results on a stratified, classâ€‘balanced test set of ten representative APT actors show 85.05â€¯% Topâ€‘1 accuracy for direct label prediction and 70.09â€¯% for the more demanding explanatory task, quantifying the tradeâ€‘off between interpretability and precision.</p>
<p align="justify">Collectively, these contributions demonstrate that vetted synthetic data + parameterâ€‘efficient fineâ€‘tuning can deliver scalable, lowâ€‘latency APT attribution that is robust to concept drift and feasible for Security Operations Centers without large compute budgets. The work closes critical gaps in previous sequenceâ€‘matching and malwareâ€‘clustering approaches by pairing richer behavioral context with a deployable model footprint, and it lays a foundation for future research on integrating cloud/mobile ATT&CK coverage and multiâ€‘modal evidence sources.</p>

[Back to the Project List](https://github.com/ntust-im-labyrinth/labyrinth/tree/GilvyThelmaProjectM/projects#----projects---colorbluelab-coloryellowy-oung--colororanger-estless-colorgreenin-colorredt-hreat-colororangeh-unting)
